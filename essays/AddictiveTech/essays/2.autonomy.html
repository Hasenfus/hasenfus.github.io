<article id="post2" class="blog-post">
    <h2>Attention, Autonomy, and the Nature of Self-Determination</h2>
    
    <p>Having established how attention operates as our cognitive steering mechanism, I want to examine what autonomy actually means and how it develops. The concept of autonomy will prove crucial for understanding how technology should interact with human agency.</p>
    
    <h3>A Thought Experiment in Agency</h3>
    
    <p>Imagine being a wasp in a universe where energy and gravity work as they do in ours. You're placed on a planet where a civilization stores their natural nectar in centralized areas. Over generations, your species has developed survival tactics to hunt, kill, and steal nectar from these stores.</p>
    
    <p>In this scenario, value is derived without intelligent self-awareness—cases where an objective function lacks sufficient control over instincts and impulses. This is where I find being part of the human race most beautiful and inspiring. We have, through fortunate evolutionary developments (opposable thumbs, high Dunbar numbers, bipedalism), broken past an emergent barrier in brain computation where we have a fuzzy but real notion of control over the placement of value and inputs that steer our wheel.</p>
    
    <h3>The Evolution of Moral Agency</h3>
    
    <p>Our objective functions were forged through the death of countless living beings before us, driven by the simple aim to perpetuate. We are patterns that perpetuate, and evolution developed keen solutions to this aim. Morality and ethics appear to be emergent properties of social beings navigating complex environments<span class="citation" data-citation="Tomasello, M. (2016). A Natural History of Human Morality. Harvard University Press."></span>.</p>
    
    <p>A curious idea: perhaps the firmware installed in us guides the orientation of impulse vectors and innate instincts. As computational capacity in the brain grows, these impulses theoretically become less impactful and eventually disconnected, allowing compute-centered intelligence to assume flexible design over moral and agential architecture.</p>
    
    <h3>AI and the Question of Rooting</h3>
    
    <p>Carl Jung once said, "you must be rooted in hell to reach for heaven."<span class="citation" data-citation="Jung, C.G. (1961). Memories, Dreams, Reflections. Pantheon Books."></span> This raises a profound question: if a system isn't a direct spawn of biological evolution, would it be rooted in the same existential foundation we biological agents share? AI systems are products of the infosphere, driven by memetics rather than genetics. They lack awareness of the utter fragility of our nature—born not from survival and the fight for life, but from abundance and a single objective: prediction.</p>
    
    <p>This difference in origins has profound implications for how AI systems should interact with human development and autonomy.</p>
    
    <h3>Towards Developmental Concerns</h3>
    
    <p>Having established what autonomy means for fully developed adults, we now face a crucial question: how do these principles apply to those who are still developing their capacity for self-determination? Children and adolescents present unique challenges that force us to think more carefully about what it means for AI systems to respect autonomy when the capacity for autonomy is still emerging.</p>
    
    <h3>References</h3>
    
    <ol>
        <li>Tomasello, M. (2016). A Natural History of Human Morality. Harvard University Press.</li>
        <li>Jung, C.G. (1961). Memories, Dreams, Reflections. Pantheon Books.</li>
    </ol>
</article>  

